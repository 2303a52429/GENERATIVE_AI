{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Write Python code from scratch to find error metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table 1. Also compare the results with the outcomes of libraries\n",
        "\n",
        "image.png"
      ],
      "metadata": {
        "id": "b5Sx7UgvjVfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "Y_actual = [20, 30, 40, 50, 60]\n",
        "Y_pred = [20.5, 30.3, 40.2, 50.6, 60.7]\n",
        "\n",
        "\n",
        "MAE= mean_absolute_error(Y_actual, Y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error : {MAE:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kDKSxgejb-A",
        "outputId": "7b85b6ed-0cb9-4e9b-bd20-e989b9c13a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error : 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEAN SQUARE ERROR"
      ],
      "metadata": {
        "id": "pEge1cvGjrv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE= mean_squared_error(Y_actual, Y_pred)\n",
        "print(f\"Mean Squared Error : {MSE:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09rxkkLnjmIP",
        "outputId": "984e1823-ea70-4e14-da36-cb5d014d8b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error : 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROOT MEAN SQUARE ERROR"
      ],
      "metadata": {
        "id": "P0sR1W68j2RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "rmse_numpy = np.sqrt(np.mean((np.array(Y_actual) - np.array(Y_pred)) ** 2))\n",
        "print(f\"RMSE using NumPy: {rmse_numpy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzotM34fj3q3",
        "outputId": "d5acd851-9c2e-48c4-f4f7-c3eda317719b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE using NumPy: 0.4960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AMONG THE 3 ERROR METRICS MSE HAS GIVEN THE LEAST ERROR = 0.25"
      ],
      "metadata": {
        "id": "5lOI9PK0j_zB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 2\n",
        "\n",
        "Write python code from scratch to find evaluation metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table 2. Also compare the results with outcome of libraries"
      ],
      "metadata": {
        "id": "dWQjoLetkIBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_actual = [0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2]\n",
        "y_pred =   [0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2]\n",
        "\n",
        "cm = confusion_matrix(y_actual, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix :\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OynhBxdbkUDi",
        "outputId": "57952637-70a1-4a05-e734-8be674eeb256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix :\n",
            " [[ 9  0  2]\n",
            " [ 1  7  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACCURACY"
      ],
      "metadata": {
        "id": "Y6arPFthkh12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_actual, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MlSXDX5kmPm",
        "outputId": "45a8a5e4-bc6e-49a1-efd4-9d174b81ed63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PRECISION"
      ],
      "metadata": {
        "id": "Ec4R0nrFk2xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(y_actual, y_pred, average='macro')\n",
        "print(f\"Precision: {precision:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-kvU-xQk9KG",
        "outputId": "a712c79a-25dc-4a16-9bce-a4d287f19db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 -SCORE"
      ],
      "metadata": {
        "id": "RGabY6ujlIqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_actual, y_pred, average='weighted')\n",
        "print(f\"F1-Score {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcDZ5A8blKCV",
        "outputId": "d4a47db7-8639-4d32-f2e8-427322f459fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECALL"
      ],
      "metadata": {
        "id": "CTHS0etAlRKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(y_actual, y_pred, average='weighted')\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v4ZpVuNlN4m",
        "outputId": "98b5ad6e-56a3-4b23-8e66-c293602a1464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.9\n"
          ]
        }
      ]
    }
  ]
}